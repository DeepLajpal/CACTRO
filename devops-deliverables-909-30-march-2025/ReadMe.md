# Log Archival Pipeline

## Overview

This project automates the archival of application logs from an EC2 instance to an S3 bucket daily. Logs are compressed and stored in the `logs/YYYY-MM-DD/` structure with versioning enabled.

## Steps Followed

1. **Launch EC2 Instance** (30 mins)
   - Created an Amazon Linux 2 EC2 instance.
   - Configured security group to allow SSH only from my IP.
2. **Set Up Log Generation** (20 mins)
   - Created a cron job to write log entries to `/var/log/app.log` every minute.
     `* * * * * echo "$(date) - AWS cron test" >> /var/log/app.log`
3. **Create and Configure S3 Bucket** (25 mins)
   - Created a private S3 bucket `cactro-test-bucket`.
   - Enabled versioning and default server-side encryption.
4. **Attach IAM Role to EC2** (20 mins)
   - Created an IAM role `EC2-S3-Access-Cactro-Test`.
   - and created a policy `EC2-S3-LEAST-ACCESS-CACTRO-TEST` Granted `s3:PutObject`, `s3:GetObject`, and `s3:ListBucket` permissions.
   - Attached the IAM role to the EC2 instance.
5. **Develop Upload Script** (40 mins)
   - Wrote a shell script to:
     - Compress the log file.
     - Upload it to S3 under `logs/YYYY-MM-DD/`.
     - Log the upload status.
   - Scheduled it via cron to run daily at midnight.
   - Cron Job `* * * * * sudo /home/ec2-user/upload_logs.sh` for testing
   - Cron Job for real scenario can be `0 0 * * * sudo /home/ec2-user/upload_logs.sh`
6. **Submit Deliverables** (2:50 mins)
   - Tested and verified the setup.
   - Collected logs and screenshots.
   - Submitted the required files.

## How to Test the Upload

- Manually run the script:
  ```bash
  /bin/bash sudo /home/ec2-user/upload_logs.sh
  ```
- Check `/var/log/upload_s3.log` for confirmation.(screenshot also attached for this)
- Verify the file in S3 under `logs/YYYY-MM-DD/app.log.gz`.

## Where to Find Uploaded Logs

- Navigate to the S3 bucket (`cactro-test-bucket`).
- Logs are stored in `logs/YYYY-MM-DD/app.log.gz`.
- Check versioning for multiple uploads.

## Deliverables files and Screenshot attached of the following:

- **S3_versioning_screenshot_with_pathname.png**: A screenshot or CLI output showing:The file in S3 under the correct path. The S3 versioning in effect.

- **ReadMe.md**: Documentation outlining the steps to set up a log archival pipeline from EC2 to S3, including testing and deliverables.

### Configuration Files

- **Ec2_Attached_POLICY.json**: IAM policy granting EC2 permissions for S3 operations (PutObject, GetObject, ListBucket) on all resources.

### Scripts

- **upload_logs.sh**: Shell script to compress application logs, upload them to S3, log the status, and clean up temporary files.

### Log Files

- **app.log**: Log file generated by a cron job, containing timestamped entries for testing AWS cron functionality.
